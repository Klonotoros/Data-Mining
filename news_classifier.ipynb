{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Klasyfikator Naive Bayes do klasyfikacji artykułów newsowych\n",
        "\n",
        "Ten notatnik zawiera klasyfikator Naive Bayes z biblioteki scikit-learn do klasyfikacji tekstu na kategorie newsowe.\n",
        "\n",
        "## Krok 1: Instalacja wymaganych bibliotek (jeśli potrzebne)\n",
        "\n",
        "Jeśli nie masz zainstalowanych bibliotek, uruchom w terminalu:\n",
        "```\n",
        "pip install scikit-learn seaborn matplotlib\n",
        "```\n",
        "\n",
        "## Krok 2: Importowanie bibliotek\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importowanie niezbędnych bibliotek\n",
        "import json  # Do wczytywania danych z pliku JSON\n",
        "from collections import Counter  # Do liczenia kategorii\n",
        "import numpy as np  # Do operacji na macierzach\n",
        "import matplotlib.pyplot as plt  # Do tworzenia wykresów\n",
        "import seaborn as sns  # Do ładnych wizualizacji statystycznych\n",
        "from sklearn.model_selection import train_test_split  # Do podziału danych\n",
        "from sklearn.naive_bayes import MultinomialNB  # Gotowy klasyfikator Naive Bayes\n",
        "from sklearn.feature_extraction.text import CountVectorizer  # Konwertuje tekst na liczby\n",
        "from sklearn.pipeline import Pipeline  # Łączy wektoryzację i klasyfikację\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report  # Metryki\n",
        "\n",
        "# Ustawienie stylu wykresów\n",
        "sns.set_style(\"whitegrid\")  # Białe tło z siatką\n",
        "plt.rcParams['figure.figsize'] = (12, 8)  # Domyślny rozmiar wykresów\n",
        "plt.rcParams['font.size'] = 10  # Rozmiar czcionki\n",
        "\n",
        "print(\"Biblioteki zaimportowane!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Krok 1: Wczytanie danych\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wczytanie danych z pliku JSON\n",
        "file_path = 'news/good_categories.json'  # Ścieżka do pliku z danymi\n",
        "\n",
        "# Otwieramy plik i wczytujemy dane\n",
        "with open(file_path, 'r', encoding='utf-8') as f:  # 'r' = tryb odczytu, 'utf-8' = kodowanie polskich znaków\n",
        "    data = json.load(f)  # Wczytuje całą zawartość pliku JSON jako listę słowników\n",
        "\n",
        "# Wyświetlenie podstawowych informacji o danych\n",
        "print(f\"Liczba artykułów: {len(data)}\")  # Ile mamy artykułów w sumie\n",
        "print(f\"Przykładowy artykuł: {data[0]}\")  # Wyświetlamy pierwszy artykuł jako przykład\n",
        "\n",
        "# Wyjaśnienie:\n",
        "# - data to lista słowników, każdy słownik ma klucze: 'text' (treść) i 'label' (kategoria)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Krok 2: Przygotowanie danych treningowych i testowych\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Podział danych na zbiór treningowy (80%) i testowy (20%)\n",
        "\n",
        "# Przygotowanie listy tekstów i etykiet\n",
        "texts = []  # Lista z tekstami artykułów\n",
        "labels = []  # Lista z kategoriami (etykietami)\n",
        "\n",
        "# Przejście przez wszystkie artykuły i wyciągnięcie tekstu i etykiety\n",
        "for article in data:\n",
        "    texts.append(article['text'])  # Dodajemy tekst artykułu\n",
        "    labels.append(article['label'])  # Dodajemy kategorię (np. \"Business\", \"Politics\")\n",
        "\n",
        "# Podział na zbiór treningowy (80%) i testowy (20%)\n",
        "# random_state=42 zapewnia, że podział będzie zawsze taki sam (do reprodukcji wyników)\n",
        "# stratify=labels zapewnia, że proporcje kategorii są zachowane w obu zbiorach\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(f\"Zbiór treningowy: {len(X_train)} artykułów\")\n",
        "print(f\"Zbiór testowy: {len(X_test)} artykułów\")\n",
        "print(f\"Kategorie w zbiorze treningowym: {Counter(y_train)}\")\n",
        "\n",
        "# Wyjaśnienie:\n",
        "# - X_train, X_test: teksty artykułów (X = cechy/features)\n",
        "# - y_train, y_test: kategorie (y = etykiety/labels)\n",
        "# - test_size=0.2 oznacza 20% danych na test, 80% na trening\n",
        "# - stratify zapewnia równomierny podział kategorii\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Krok 3: Utworzenie i trenowanie klasyfikatora Naive Bayes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utworzenie pipeline'u\n",
        "# Pipeline automatycznie wykonuje: wektoryzacja -> klasyfikacja\n",
        "# CountVectorizer: zamienia tekst na macierz liczb (każde słowo = kolumna, liczba wystąpień = wartość)\n",
        "# MultinomialNB: gotowy klasyfikator Naive Bayes dla danych tekstowych\n",
        "\n",
        "classifier = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(\n",
        "        lowercase=True,        # Zamienia na małe litery\n",
        "        token_pattern=r'\\b[a-z]+\\b',  # Wzorzec dla słów (tylko litery)\n",
        "        min_df=2,             # Ignoruj słowa występujące w mniej niż 2 dokumentach\n",
        "        max_features=10000    # Maksymalnie 10000 najczęstszych słów\n",
        "    )),\n",
        "    ('classifier', MultinomialNB(alpha=1.0))  # alpha=1.0 to wygładzanie Laplace'a\n",
        "])\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"KLASYKATOR NAIVE BAYES Z SCIKIT-LEARN\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nTrenowanie klasyfikatora...\")\n",
        "\n",
        "# Trenowanie (automatycznie wykonuje wektoryzację i trening)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"✓ Wytrenowano!\")\n",
        "print(f\"Liczba cech (słów): {len(classifier.named_steps['vectorizer'].vocabulary_)}\")\n",
        "\n",
        "# Wyjaśnienie:\n",
        "# - Pipeline łączy wektoryzację i klasyfikację w jeden proces\n",
        "# - CountVectorizer automatycznie konwertuje tekst na liczby\n",
        "# - MultinomialNB to zoptymalizowany algorytm Naive Bayes\n",
        "# - alpha=1.0 to wygładzanie Laplace'a (zapobiega zerowym prawdopodobieństwom)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Krok 4: Przewidywanie i ocena klasyfikatora\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Przewidywanie kategorii dla zbioru testowego\n",
        "print(\"Przewidywanie kategorii dla zbioru testowego...\")\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "# Obliczenie dokładności\n",
        "accuracy = accuracy_score(y_test, predictions) * 100\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"DOKŁADNOŚĆ: {accuracy:.2f}%\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Szczegółowy raport klasyfikacji\n",
        "print(\"\\nSzczegółowy raport klasyfikacji:\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Wyjaśnienie:\n",
        "# - predictions: lista przewidzianych kategorii\n",
        "# - accuracy_score: oblicza dokładność automatycznie\n",
        "# - classification_report: pokazuje precision, recall, f1-score dla każdej kategorii\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Krok 5: Wizualizacja macierzy pomyłek\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "# Obliczenie macierzy pomyłek — upewniamy się, że etykiety są spójne\n",
        "labels = list(unique_labels(y_test, predictions))           # etykiety w używanej kolejności\n",
        "cm = confusion_matrix(y_test, predictions, labels=labels)  # wymuszamy tę samą kolejność\n",
        "categories = labels                                        # używamy tej listy dalej\n",
        "\n",
        "# Tworzenie wykresu macierzy pomyłek\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(\n",
        "    cm,  # Macierz pomyłek\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    xticklabels=categories,\n",
        "    yticklabels=categories,\n",
        "    cbar_kws={'label': 'Liczba próbek'},\n",
        "    linewidths=0.5,\n",
        "    linecolor='gray'\n",
        ")\n",
        "plt.title('Macierz pomyłek - Klasyfikacja artykułów newsowych', fontsize=16, pad=20)\n",
        "plt.xlabel('Przewidziana kategoria', fontsize=12)\n",
        "plt.ylabel('Rzeczywista kategoria', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Dla każdej kategorii obliczamy precision, recall i accuracy\n",
        "print(\"\\nSzczegółowe statystyki dla każdej kategorii:\")\n",
        "print(\"=\"*80)\n",
        "for i, category in enumerate(categories):\n",
        "    tp = cm[i, i]\n",
        "    fp = cm[:, i].sum() - tp\n",
        "    fn = cm[i, :].sum() - tp\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    accuracy_cat = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n",
        "\n",
        "    print(f\"\\n{category}:\")\n",
        "    print(f\"  Poprawne przewidywania: {tp}\")\n",
        "    print(f\"  Błędne przewidywania: {fp + fn}\")\n",
        "    print(f\"  Precision: {precision*100:.2f}%\")\n",
        "    print(f\"  Recall: {recall*100:.2f}%\")\n",
        "    print(f\"  Accuracy: {accuracy_cat*100:.2f}%\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Wyjaśnienie:\n",
        "# - Macierz pomyłek pokazuje, ile razy każda kategoria została poprawnie/niepoprawnie przewidziana\n",
        "# - Na przekątnej są poprawne przewidywania\n",
        "# - Poza przekątną są błędy klasyfikacji\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
