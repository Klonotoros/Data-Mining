{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Klasyfikator Naive Bayes do klasyfikacji artykułów newsowych\n",
        "\n",
        "Ten notatnik zawiera klasyfikator Naive Bayes z biblioteki scikit-learn do klasyfikacji tekstu artykułów newsowych na kategorie.\n",
        "\n",
        "## Krok 1: Instalacja wymaganych bibliotek (jeśli potrzebne)\n",
        "\n",
        "Jeśli nie masz zainstalowanych bibliotek, uruchom w terminalu:\n",
        "```\n",
        "pip install scikit-learn seaborn matplotlib\n",
        "```\n",
        "\n",
        "## Krok 2: Importowanie bibliotek\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importowanie niezbędnych bibliotek\n",
        "import json  # Do wczytywania danych z pliku JSON\n",
        "from collections import Counter  # Do liczenia kategorii\n",
        "import numpy as np  # Do operacji na macierzach\n",
        "import matplotlib.pyplot as plt  # Do tworzenia wykresów\n",
        "import seaborn as sns  # Do ładnych wizualizacji statystycznych\n",
        "from sklearn.model_selection import train_test_split  # Do podziału danych\n",
        "from sklearn.naive_bayes import MultinomialNB  # Gotowy klasyfikator Naive Bayes\n",
        "from sklearn.feature_extraction.text import CountVectorizer  # Konwertuje tekst na liczby\n",
        "from sklearn.pipeline import Pipeline  # Łączy wektoryzację i klasyfikację\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report  # Metryki\n",
        "\n",
        "# Ustawienie stylu wykresów\n",
        "sns.set_style(\"whitegrid\")  # Białe tło z siatką\n",
        "plt.rcParams['figure.figsize'] = (12, 8)  # Domyślny rozmiar wykresów\n",
        "plt.rcParams['font.size'] = 10  # Rozmiar czcionki\n",
        "\n",
        "print(\"Biblioteki zaimportowane!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Krok 3: Wczytanie danych z newsLabeled.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wczytanie danych z pliku JSON\n",
        "file_path = 'news/newsLabeled.json'  # Ścieżka do pliku z danymi\n",
        "\n",
        "# Otwieramy plik i wczytujemy dane\n",
        "with open(file_path, 'r', encoding='utf-8') as f:  # 'r' = tryb odczytu, 'utf-8' = kodowanie polskich znaków\n",
        "    data = json.load(f)  # Wczytuje całą zawartość pliku JSON jako listę słowników\n",
        "\n",
        "# Wyświetlenie podstawowych informacji o danych\n",
        "print(f\"Liczba artykułów: {len(data)}\")  # Ile mamy artykułów w sumie\n",
        "print(f\"Przykładowy artykuł: {data[0]}\")  # Wyświetlamy pierwszy artykuł jako przykład\n",
        "\n",
        "# Wyjaśnienie:\n",
        "# - data to lista słowników, każdy słownik ma klucze: 'text' (treść) i 'label' (kategoria)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Krok 4: Filtrowanie danych - usunięcie artykułów z etykietą \"unknown\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtrowanie danych - usuwamy artykuły z etykietą \"unknown\"\n",
        "filtered_data = [article for article in data if article.get('label', 'unknown') != 'unknown']\n",
        "\n",
        "print(f\"Liczba artykułów przed filtrowaniem: {len(data)}\")\n",
        "print(f\"Liczba artykułów po filtrowaniu (bez 'unknown'): {len(filtered_data)}\")\n",
        "print(f\"Usunięto {len(data) - len(filtered_data)} artykułów z etykietą 'unknown'\")\n",
        "\n",
        "# Liczenie kategorii\n",
        "label_counts = Counter([article['label'] for article in filtered_data])\n",
        "print(f\"\\nLiczba unikalnych kategorii: {len(label_counts)}\")\n",
        "print(\"\\nRozkład kategorii:\")\n",
        "print(\"-\" * 60)\n",
        "for label, count in sorted(label_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"  {label:<30} {count:>10}\")\n",
        "\n",
        "# Wyjaśnienie:\n",
        "# - Filtrujemy dane, aby usunąć artykuły z etykietą \"unknown\"\n",
        "# - Te artykuły nie będą używane do treningu, ale model może je później klasyfikować\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Krok 5: Przygotowanie danych treningowych i testowych\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Podział danych na zbiór treningowy (80%) i testowy (20%)\n",
        "\n",
        "# Przygotowanie listy tekstów i etykiet\n",
        "texts = []  # Lista z tekstami artykułów\n",
        "labels = []  # Lista z kategoriami (etykietami)\n",
        "\n",
        "# Przejście przez wszystkie artykuły i wyciągnięcie tekstu i etykiety\n",
        "for article in filtered_data:\n",
        "    texts.append(article['text'])  # Dodajemy tekst artykułu\n",
        "    labels.append(article['label'])  # Dodajemy kategorię (np. \"Business\", \"Politics\")\n",
        "\n",
        "# Podział na zbiór treningowy (80%) i testowy (20%)\n",
        "# random_state=42 zapewnia, że podział będzie zawsze taki sam (do reprodukcji wyników)\n",
        "# stratify=labels zapewnia, że proporcje kategorii są zachowane w obu zbiorach\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(f\"Zbiór treningowy: {len(X_train)} artykułów\")\n",
        "print(f\"Zbiór testowy: {len(X_test)} artykułów\")\n",
        "print(f\"Kategorie w zbiorze treningowym: {Counter(y_train)}\")\n",
        "\n",
        "# Wyjaśnienie:\n",
        "# - X_train, X_test: teksty artykułów (X = cechy/features)\n",
        "# - y_train, y_test: kategorie (y = etykiety/labels)\n",
        "# - test_size=0.2 oznacza 20% danych na test, 80% na trening\n",
        "# - stratify zapewnia równomierny podział kategorii\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Krok 6: Utworzenie i trenowanie klasyfikatora Naive Bayes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utworzenie pipeline'u\n",
        "# Pipeline automatycznie wykonuje: wektoryzacja -> klasyfikacja\n",
        "# CountVectorizer: zamienia tekst na macierz liczb (każde słowo = kolumna, liczba wystąpień = wartość)\n",
        "# MultinomialNB: gotowy klasyfikator Naive Bayes dla danych tekstowych\n",
        "\n",
        "classifier = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(\n",
        "        lowercase=True,        # Zamienia na małe litery\n",
        "        token_pattern=r'\\b[a-z]+\\b',  # Wzorzec dla słów (tylko litery)\n",
        "        min_df=2,             # Ignoruj słowa występujące w mniej niż 2 dokumentach\n",
        "        max_features=10000    # Maksymalnie 10000 najczęstszych słów\n",
        "    )),\n",
        "    ('classifier', MultinomialNB(alpha=1.0))  # alpha=1.0 to wygładzanie Laplace'a\n",
        "])\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"KLASYKATOR NAIVE BAYES Z SCIKIT-LEARN\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nTrenowanie klasyfikatora...\")\n",
        "\n",
        "# Trenowanie (automatycznie wykonuje wektoryzację i trening)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"✓ Wytrenowano!\")\n",
        "print(f\"Liczba cech (słów): {len(classifier.named_steps['vectorizer'].vocabulary_)}\")\n",
        "\n",
        "# Wyjaśnienie:\n",
        "# - Pipeline łączy wektoryzację i klasyfikację w jeden proces\n",
        "# - CountVectorizer automatycznie konwertuje tekst na liczby\n",
        "# - MultinomialNB to zoptymalizowany algorytm Naive Bayes\n",
        "# - alpha=1.0 to wygładzanie Laplace'a (zapobiega zerowym prawdopodobieństwom)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Krok 7: Przewidywanie i ocena klasyfikatora\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Przewidywanie kategorii dla zbioru testowego\n",
        "print(\"Przewidywanie kategorii dla zbioru testowego...\")\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "# Obliczenie dokładności\n",
        "accuracy = accuracy_score(y_test, predictions) * 100\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"DOKŁADNOŚĆ: {accuracy:.2f}%\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Szczegółowy raport klasyfikacji\n",
        "print(\"\\nSzczegółowy raport klasyfikacji:\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Wyjaśnienie:\n",
        "# - predictions: lista przewidzianych kategorii\n",
        "# - accuracy_score: oblicza dokładność automatycznie\n",
        "# - classification_report: pokazuje precision, recall, f1-score dla każdej kategorii\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Krok 8: Wizualizacja macierzy pomyłek\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "# Obliczenie macierzy pomyłek — upewniamy się, że etykiety są spójne\n",
        "labels_list = list(unique_labels(y_test, predictions))  # etykiety w używanej kolejności\n",
        "cm = confusion_matrix(y_test, predictions, labels=labels_list)  # wymuszamy tę samą kolejność\n",
        "categories = labels_list  # używamy tej listy dalej\n",
        "\n",
        "# Tworzenie wykresu macierzy pomyłek\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(\n",
        "    cm,  # Macierz pomyłek\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    xticklabels=categories,\n",
        "    yticklabels=categories,\n",
        "    cbar_kws={'label': 'Liczba próbek'},\n",
        "    linewidths=0.5,\n",
        "    linecolor='gray'\n",
        ")\n",
        "plt.title('Macierz pomyłek - Klasyfikacja artykułów newsowych', fontsize=16, pad=20)\n",
        "plt.xlabel('Przewidziana kategoria', fontsize=12)\n",
        "plt.ylabel('Rzeczywista kategoria', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Dla każdej kategorii obliczamy precision, recall i accuracy\n",
        "print(\"\\nSzczegółowe statystyki dla każdej kategorii:\")\n",
        "print(\"=\"*80)\n",
        "for i, category in enumerate(categories):\n",
        "    tp = cm[i, i]\n",
        "    fp = cm[:, i].sum() - tp\n",
        "    fn = cm[i, :].sum() - tp\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    accuracy_cat = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n",
        "\n",
        "    print(f\"\\n{category}:\")\n",
        "    print(f\"  Poprawne przewidywania: {tp}\")\n",
        "    print(f\"  Błędne przewidywania: {fp + fn}\")\n",
        "    print(f\"  Precision: {precision*100:.2f}%\")\n",
        "    print(f\"  Recall: {recall*100:.2f}%\")\n",
        "    print(f\"  Accuracy: {accuracy_cat*100:.2f}%\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Wyjaśnienie:\n",
        "# - Macierz pomyłek pokazuje, ile razy każda kategoria została poprawnie/niepoprawnie przewidziana\n",
        "# - Na przekątnej są poprawne przewidywania\n",
        "# - Poza przekątną są błędy klasyfikacji\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Krok 9: Klasyfikacja własnego tekstu\n",
        "\n",
        "Wprowadź tekst artykułu poniżej, a model przewidzi jego kategorię.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wprowadź tekst artykułu do klasyfikacji\n",
        "article_text = \"\"\"\n",
        "Wprowadź tutaj tekst artykułu, który chcesz sklasyfikować.\n",
        "Na przykład:\n",
        "\"Technology companies are investing heavily in artificial intelligence research...\"\n",
        "\"\"\"\n",
        "\n",
        "# Przewidywanie kategorii\n",
        "predicted_label = classifier.predict([article_text])[0]\n",
        "predicted_proba = classifier.predict_proba([article_text])[0]\n",
        "\n",
        "# Pobranie wszystkich możliwych kategorii\n",
        "all_labels = classifier.classes_\n",
        "\n",
        "# Utworzenie słownika z prawdopodobieństwami\n",
        "probabilities = dict(zip(all_labels, predicted_proba))\n",
        "\n",
        "# Sortowanie według prawdopodobieństwa (malejąco)\n",
        "sorted_probs = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"WYNIK KLASYFIKACJI\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nPrzewidziana kategoria: {predicted_label}\")\n",
        "print(f\"Prawdopodobieństwo: {probabilities[predicted_label]*100:.2f}%\")\n",
        "print(\"\\nWszystkie kategorie (posortowane według prawdopodobieństwa):\")\n",
        "print(\"-\" * 80)\n",
        "for label, prob in sorted_probs[:10]:  # Top 10 kategorii\n",
        "    print(f\"  {label:<30} {prob*100:>6.2f}%\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Przykład użycia\n",
        "\n",
        "Poniżej znajduje się przykład klasyfikacji przykładowego tekstu:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Przykładowy tekst do klasyfikacji\n",
        "example_text = \"\"\"\n",
        "The Bank of England has raised interest rates to their highest level in 15 years \n",
        "as it continues to battle rising prices. The Monetary Policy Committee voted to \n",
        "increase the base rate from 4.5% to 5% - the 13th consecutive rise. The move \n",
        "comes as inflation remains stubbornly high at 8.7%, well above the Bank's 2% target.\n",
        "\"\"\"\n",
        "\n",
        "# Klasyfikacja\n",
        "predicted = classifier.predict([example_text])[0]\n",
        "proba = classifier.predict_proba([example_text])[0]\n",
        "probabilities = dict(zip(classifier.classes_, proba))\n",
        "sorted_probs = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"PRZYKŁAD KLASYFIKACJI\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTekst artykułu:\")\n",
        "print(f\"'{example_text[:200]}...'\")\n",
        "print(f\"\\nPrzewidziana kategoria: {predicted}\")\n",
        "print(f\"Prawdopodobieństwo: {probabilities[predicted]*100:.2f}%\")\n",
        "print(\"\\nTop 5 kategorii:\")\n",
        "print(\"-\" * 80)\n",
        "for label, prob in sorted_probs[:5]:\n",
        "    print(f\"  {label:<30} {prob*100:>6.2f}%\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
